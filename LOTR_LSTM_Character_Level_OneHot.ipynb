{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "gradient": {
     "editing": false,
     "id": "1fe2ae7d-6d6d-4216-bf57-e31a43ee07f8",
     "kernelId": ""
    },
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/bengsoon/lstm_lord_of_the_rings/blob/main/LOTR_LSTM_Character_Level_OneHot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "3c8f437f-6d7a-404a-9173-88458dc55ec6",
     "kernelId": ""
    },
    "id": "sBQN-dtIGzPk"
   },
   "source": [
    "## Creating a Language Model with LSTM using Lord of The Rings Corpus\n",
    "In this notebook, we will create a character-level language language model using LSTM using **one-hot encoding** on the input vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "d862b356-f5f3-461b-9c1b-1c86f24bc490",
     "kernelId": ""
    },
    "id": "BwvwLm9wnCwc"
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "7552effa-3565-4e47-b1d4-80fac5b275be",
     "kernelId": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow==2.7.0\n",
      "  Downloading tensorflow-2.7.0-cp38-cp38-manylinux2010_x86_64.whl (489.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 489.6 MB 26 kB/s  eta 0:00:011    |█████▏                          | 78.6 MB 9.9 MB/s eta 0:00:42     |█████▋                          | 85.5 MB 9.9 MB/s eta 0:00:41     |█████▊                          | 87.3 MB 9.9 MB/s eta 0:00:41     |██████▎                         | 95.8 MB 9.6 MB/s eta 0:00:41     |██████▊                         | 102.1 MB 9.6 MB/s eta 0:00:41     |█████████▏                      | 140.0 MB 8.3 MB/s eta 0:00:43     |█████████▌                      | 146.1 MB 23.1 MB/s eta 0:00:15     |█████████████▌                  | 206.4 MB 9.1 MB/s eta 0:00:32███▎                 | 219.3 MB 5.4 MB/s eta 0:00:51     |██████████████▋                 | 224.3 MB 5.4 MB/s eta 0:00:50     |██████████████████▍             | 280.7 MB 24.5 MB/s eta 0:00:09     |██████████████████▋             | 285.5 MB 24.5 MB/s eta 0:00:09     |██████████████████▊             | 286.6 MB 24.5 MB/s eta 0:00:09     |███████████████████▍            | 296.6 MB 24.5 MB/s eta 0:00:08     |█████████████████████▌          | 328.8 MB 7.7 MB/s eta 0:00:21     |██████████████████████▏         | 339.7 MB 7.7 MB/s eta 0:00:20�██████████▎        | 356.1 MB 27.3 MB/s eta 0:00:05██████████████████████▎       | 371.6 MB 27.0 MB/s eta 0:00:05     |█████████████████████████       | 382.4 MB 27.0 MB/s eta 0:00:04��███     | 412.6 MB 88.0 MB/s eta 0:00:01     |███████████████████████████▌    | 420.7 MB 83.4 MB/s eta 0:00:01422.2 MB 83.4 MB/s eta 0:00:01     |███████████████████████████▊    | 423.7 MB 83.4 MB/s eta 0:00:01:00:01�█████████████    | 428.8 MB 83.4 MB/s eta 0:00:01██████████████████▏   | 430.5 MB 83.4 MB/s eta 0:00:01     |████████████████████████████▎   | 432.3 MB 83.4 MB/s eta 0:00:01     |██████████████████████████████  | 459.9 MB 88.2 MB/s eta 0:00:01     |██████████████████████████████▊ | 469.5 MB 20.7 MB/s eta 0:00:01     |██████████████████████████████▉ | 471.4 MB 20.7 MB/s eta 0:00:01��███████████▎| 478.6 MB 20.7 MB/s eta 0:00:01��███████████▍| 480.4 MB 20.7 MB/s eta 0:00:01�█████████████████████████▊| 484.9 MB 1.7 MB/s eta 0:00:03\n",
      "\u001b[?25hCollecting numpy==1.19.5\n",
      "  Downloading numpy-1.19.5-cp38-cp38-manylinux2010_x86_64.whl (14.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 14.9 MB 26.4 MB/s eta 0:00:01 MB 26.4 MB/s eta 0:00:01            | 5.0 MB 26.4 MB/s eta 0:00:01███████████▍          | 9.9 MB 26.4 MB/s eta 0:00:01�████████████████   | 13.5 MB 26.4 MB/s eta 0:00:01 MB 26.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting regex\n",
      "  Downloading regex-2021.11.10-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (764 kB)\n",
      "\u001b[K     |████████████████████████████████| 764 kB 26.8 MB/s eta 0:00:010:00:01\n",
      "\u001b[?25hRequirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.7.0->-r requirements.txt (line 2)) (1.12.1)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.7.0->-r requirements.txt (line 2)) (1.1.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.7.0->-r requirements.txt (line 2)) (3.1.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.7.0->-r requirements.txt (line 2)) (0.2.0)\n",
      "Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.7.0->-r requirements.txt (line 2)) (2.6.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.7.0->-r requirements.txt (line 2)) (1.1.2)\n",
      "Collecting libclang>=9.0.1\n",
      "  Downloading libclang-12.0.0-py2.py3-none-manylinux1_x86_64.whl (13.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 13.4 MB 26.4 MB/s eta 0:00:01|██▎                             | 972 kB 26.4 MB/s eta 0:00:01 0:00:01ta 0:00:01     |████████████████████▏           | 8.4 MB 26.4 MB/s eta 0:00:01     |██████████████████████████▍     | 11.0 MB 26.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.7.0->-r requirements.txt (line 2)) (3.7.4.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.32.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.7.0->-r requirements.txt (line 2)) (0.37.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.7.0->-r requirements.txt (line 2)) (1.15.0)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.21.0\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.22.0-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 15.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.7.0->-r requirements.txt (line 2)) (3.3.0)\n",
      "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.7.0->-r requirements.txt (line 2)) (1.12)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.7.0->-r requirements.txt (line 2)) (1.39.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.7.0->-r requirements.txt (line 2)) (3.17.3)\n",
      "Requirement already satisfied: gast<0.5.0,>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.7.0->-r requirements.txt (line 2)) (0.4.0)\n",
      "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.7.0->-r requirements.txt (line 2)) (0.12.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.7.0->-r requirements.txt (line 2)) (1.6.3)\n",
      "Collecting tensorflow-estimator<2.8,~=2.7.0rc0\n",
      "  Downloading tensorflow_estimator-2.7.0-py2.py3-none-any.whl (463 kB)\n",
      "\u001b[K     |████████████████████████████████| 463 kB 18.9 MB/s eta 0:00:01225 kB 18.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting keras<2.8,>=2.7.0rc0\n",
      "  Downloading keras-2.7.0-py2.py3-none-any.whl (1.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.3 MB 1.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.8/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0->-r requirements.txt (line 2)) (2.0.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0->-r requirements.txt (line 2)) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0->-r requirements.txt (line 2)) (1.8.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0->-r requirements.txt (line 2)) (58.1.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0->-r requirements.txt (line 2)) (3.3.4)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0->-r requirements.txt (line 2)) (0.4.6)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0->-r requirements.txt (line 2)) (2.26.0)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0->-r requirements.txt (line 2)) (1.35.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow==2.7.0->-r requirements.txt (line 2)) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow==2.7.0->-r requirements.txt (line 2)) (4.7.2)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow==2.7.0->-r requirements.txt (line 2)) (4.2.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow==2.7.0->-r requirements.txt (line 2)) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow==2.7.0->-r requirements.txt (line 2)) (0.4.8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow==2.7.0->-r requirements.txt (line 2)) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow==2.7.0->-r requirements.txt (line 2)) (2021.5.30)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow==2.7.0->-r requirements.txt (line 2)) (3.2)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow==2.7.0->-r requirements.txt (line 2)) (2.0.6)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow==2.7.0->-r requirements.txt (line 2)) (3.1.1)\n",
      "Installing collected packages: numpy, tensorflow-io-gcs-filesystem, tensorflow-estimator, libclang, keras, tensorflow, regex\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.19.4\n",
      "    Uninstalling numpy-1.19.4:\n",
      "      Successfully uninstalled numpy-1.19.4\n",
      "  Attempting uninstall: tensorflow-estimator\n",
      "    Found existing installation: tensorflow-estimator 2.6.0\n",
      "    Uninstalling tensorflow-estimator-2.6.0:\n",
      "      Successfully uninstalled tensorflow-estimator-2.6.0\n",
      "  Attempting uninstall: keras\n",
      "    Found existing installation: keras 2.6.0\n",
      "    Uninstalling keras-2.6.0:\n",
      "      Successfully uninstalled keras-2.6.0\n",
      "  Attempting uninstall: tensorflow\n",
      "    Found existing installation: tensorflow 2.6.0+nv\n",
      "    Uninstalling tensorflow-2.6.0+nv:\n",
      "      Successfully uninstalled tensorflow-2.6.0+nv\n",
      "Successfully installed keras-2.7.0 libclang-12.0.0 numpy-1.19.5 regex-2021.11.10 tensorflow-2.7.0 tensorflow-estimator-2.7.0 tensorflow-io-gcs-filesystem-0.22.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# run this if you're running through paperspace\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "67c95a2c-4097-497f-9497-ab9626e8a18a",
     "kernelId": ""
    },
    "id": "6BvOxVto4pzg"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "from tensorflow.keras.layers import Embedding, Input, LSTM, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler, ModelCheckpoint\n",
    "from tensorflow.keras import Model\n",
    "import numpy as np \n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "from pprint import pprint as pp\n",
    "from string import punctuation\n",
    "import regex as re\n",
    "import random\n",
    "import os\n",
    "from pathlib import Path\n",
    "import math\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "78f9fc2f-3e38-418c-a7e3-230c49911bfe",
     "kernelId": ""
    },
    "id": "sMsUyeLHnFZC"
   },
   "source": [
    "### Data Preprocessing & Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "ae9df455-95a5-4c93-ade9-de60e919bc9d",
     "kernelId": ""
    },
    "id": "t4_puY1vH-Jv"
   },
   "outputs": [],
   "source": [
    "# get LOTR full text\n",
    "# !wget https://raw.githubusercontent.com/bengsoon/lstm_lord_of_the_rings/main/lotr_full.txt -P /content/drive/MyDrive/Colab\\ Notebooks/LOTR_LSTM/data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "22a0e94d-2189-4c80-82b8-8de6416d8486",
     "kernelId": ""
    },
    "id": "s065iL9iBq_A"
   },
   "source": [
    "#### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "12cb95fe-b15a-4742-942c-c09ca8a76ac1",
     "kernelId": ""
    },
    "id": "SIYll8_1BycF"
   },
   "outputs": [],
   "source": [
    "path = Path(r\"./\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "gradient": {
     "editing": false,
     "id": "1ba16b44-906f-40c0-af14-8c7a06d39821",
     "kernelId": ""
    },
    "id": "8IVk7GxXn40r",
    "outputId": "a85132ac-4d97-4f97-e2c5-a7b360258a07"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Three Rings for the Elven-kings under the sky,\n",
      "               Seven for the Dwarf-lords in their halls of stone,\n",
      "            Nine for Mortal Men doomed to die,\n",
      "              One for the Dark Lord on his dark throne\n",
      "           In the Land of Mordor where the Shadows lie.\n",
      "               One Ring to rule them all, One Ring to find them,\n",
      "               One Ring to bring them all and in the darkness bind them\n",
      "           In the Land of Mordor where the Shadows lie.\n",
      "           \n",
      "FOREWORD\n",
      "\n",
      "This tale grew in the telling, until it became a history of the Great War of the Ring and included many glimpses of the yet more ancient history that preceded it. It was begun soon after _The Hobbit_ was written and before its publication in 1937; but I did not go on with this sequel, for I wished first to complete and set in order the mythology and legends of the Elder Days, which had then been taking shape for some years. I desired to do this for my own satisfaction, and I had little hope that other people \n"
     ]
    }
   ],
   "source": [
    "with open(path/ \"data/lotr_full.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    text = f.read()\n",
    "print(text[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "gradient": {
     "editing": false,
     "id": "44cb50da-b565-4b39-9a25-c8b74adc9a31",
     "kernelId": ""
    },
    "id": "RjEFSBDEofqz",
    "outputId": "1d9943ee-adda-456b-c8a0-4e078493d337"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus length: 1532.723 K characters\n"
     ]
    }
   ],
   "source": [
    "print(f\"Corpus length: {int(len(text)) / 1000 } K characters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "45b89d55-3d3b-406f-b5fb-77ee4fbde7b6",
     "kernelId": ""
    },
    "id": "utmzz69cqNJ6"
   },
   "source": [
    "## One-Hot Encoding Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "7fdae940-8573-4659-b84b-f987d90af1c2",
     "kernelId": ""
    },
    "id": "b6KDl30qtgNe"
   },
   "outputs": [],
   "source": [
    "def standardize_text_string(text: str):\n",
    "    \"\"\"\n",
    "        create a custom standardization that:\n",
    "            1. Fixes whitespaces \n",
    "            2. Removes punctuations & numbers\n",
    "            3. Sets all texts to lowercase\n",
    "            4. Preserves the Elvish characters\n",
    "    \"\"\"\n",
    "    \n",
    "    text = re.sub(r\"[\\s+]\", \" \", text)\n",
    "    text = re.sub(r\"[0-9]\", \"\", text)\n",
    "    text = re.sub(f\"[{punctuation}–]\", \"\", text)\n",
    "\n",
    "    return text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "91f222d5-e339-4fe6-bae0-9d603ca30bee",
     "kernelId": ""
    },
    "id": "hEqgIvEtssNP"
   },
   "outputs": [],
   "source": [
    "# get unique characters in the text\n",
    "chars = sorted(set(standardize_text_string(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "gradient": {
     "editing": false,
     "id": "757d1fc4-7294-4d10-add8-c5c4c1a7b306",
     "kernelId": ""
    },
    "id": "pQpwILNTtaXn",
    "outputId": "dc6358b9-3843-41ae-bb4f-084f33debdca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' ', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'á', 'â', 'ä', 'é', 'ë', 'í', 'ó', 'ú', 'û'] \n",
      "\n",
      "Total unique characters: 36\n"
     ]
    }
   ],
   "source": [
    "print(chars, f\"\\n\\nTotal unique characters: {len(chars)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "780309e8-d5b1-4ce4-b925-197f2a4cb176",
     "kernelId": ""
    },
    "id": "6N5boivwtbF4"
   },
   "outputs": [],
   "source": [
    "# create dictionary mappings for chars to integers for vectorization & vice versa\n",
    "char2int = {c: i for i, c in enumerate(chars)}\n",
    "int2char = {i: c for c, i in char2int.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "gradient": {
     "id": "530ccd9e-1f24-4c4b-8198-f36965c8a8ff",
     "kernelId": ""
    },
    "id": "ppDB2eqWujEi",
    "outputId": "813fbf60-fda2-4ece-e510-cfe6f6393f81"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{' ': 0, 'a': 1, 'b': 2, 'c': 3, 'd': 4, 'e': 5, 'f': 6, 'g': 7, 'h': 8, 'i': 9, 'j': 10, 'k': 11, 'l': 12, 'm': 13, 'n': 14, 'o': 15, 'p': 16, 'q': 17, 'r': 18, 's': 19, 't': 20, 'u': 21, 'v': 22, 'w': 23, 'x': 24, 'y': 25, 'z': 26, 'á': 27, 'â': 28, 'ä': 29, 'é': 30, 'ë': 31, 'í': 32, 'ó': 33, 'ú': 34, 'û': 35}\n",
      "{0: ' ', 1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z', 27: 'á', 28: 'â', 29: 'ä', 30: 'é', 31: 'ë', 32: 'í', 33: 'ó', 34: 'ú', 35: 'û'}\n"
     ]
    }
   ],
   "source": [
    "print(char2int)\n",
    "print(int2char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "id": "cb39ef1c-48ed-4e82-8d50-8bd40609a57c",
     "kernelId": ""
    },
    "id": "mT7z5iWW35B2"
   },
   "outputs": [],
   "source": [
    "#let's standardize our original text\n",
    "standardized_text = standardize_text_string(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "id": "e9f248c2-ec48-41d4-9ae2-5be9a2546dcf",
     "kernelId": ""
    },
    "id": "zklBFovrshdU"
   },
   "outputs": [],
   "source": [
    "# setting up sequence length and step to create dataset\n",
    "MAX_SEQ_LEN = 20\n",
    "step = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x1MKin6j6RZX"
   },
   "source": [
    "Let's create our training examples from `standardized_text`. The input would be `sentences` where it is 'sampled' for `MAX_SEQ_LEN at every `step` from the length of the text.\n",
    "\n",
    "The output would be `next_chars` where it is the 'supposed' character the model should predict during the training time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "gradient": {
     "id": "3215a480-d35f-45b0-99c2-4d416f973cb4",
     "kernelId": ""
    },
    "id": "P7KPwJgw6IvB",
    "outputId": "ca6539c0-8f9d-4e5f-bcec-6d348dbba44b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of training examples: 736848\n"
     ]
    }
   ],
   "source": [
    "# create training examples: input (`sentences`) and output (`next_chars`)\n",
    "sentences = []\n",
    "next_chars = []\n",
    "\n",
    "for i in range(0, len(standardized_text) - MAX_SEQ_LEN, step):\n",
    "    sentences.append(standardized_text[i: i + MAX_SEQ_LEN])\n",
    "    next_chars.append(standardized_text[i + MAX_SEQ_LEN])\n",
    "\n",
    "print(\"Total number of training examples:\", len(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "id": "7c841ce5-2f6e-4291-ba68-0769f2068862",
     "kernelId": ""
    },
    "id": "auq1fW8ZulLl"
   },
   "outputs": [],
   "source": [
    "# get the total number of unique chars\n",
    "# these parameters will also be used later on in our model\n",
    "N_UNIQUE_CHARS = len(chars)\n",
    "m = len(sentences)\n",
    "\n",
    "def vectorize_sentence(text, max_seq_len=MAX_SEQ_LEN, n_unique_chars=N_UNIQUE_CHARS):\n",
    "    \"\"\" Convert input sentence into one-hot encoding numpy vector of shape \n",
    "     (m, max_seq_len, n_unique_chars) \"\"\"\n",
    "    if type(text) == str:\n",
    "        # if text is input as string\n",
    "        if len(text) > max_seq_len:\n",
    "            # if text is longer than max_seq_len it will be truncated \n",
    "            ## and appended on the list\n",
    "            text_list = []\n",
    "            for i in range(0, len(text), max_seq_len):\n",
    "                text_list.append(text[i: i+max_seq_len])\n",
    "            text = text_list\n",
    "        else:\n",
    "            # if text is less than max_seq_len, convert str -> list(str)\n",
    "            text = [text]\n",
    "        \n",
    "    \n",
    "    m = len(text) # get total number of sentences\n",
    "\n",
    "    x = np.zeros((m, max_seq_len, n_unique_chars), dtype=np.bool)\n",
    "    for i, sentence in enumerate(text):\n",
    "        # for each sentence in the `text` list\n",
    "        for p, char in enumerate(sentence.lower()): \n",
    "            # p is the position of the letter in the sentence\n",
    "            # char is the character in the sentence\n",
    "            x[i, p, char2int[char]] = 1\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "gradient": {
     "id": "e21e0faf-afcb-442c-9b0f-06fd69bcd946",
     "kernelId": ""
    },
    "id": "nmGPT_egvTr7",
    "outputId": "03966279-b9e7-4ffb-9e35-651ae59901d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of text vector: (3, 20, 36)\n",
      "Supposed shape:(3, 20, 36)\n"
     ]
    }
   ],
   "source": [
    "# try out sentence to ensure we get the right shape\n",
    "text_test = \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\" + \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\".lower()\n",
    "\n",
    "text_test_vector = vectorize_sentence(text_test)\n",
    "print(\"Shape of text vector: {}\".format(text_test_vector.shape))\n",
    "print(f\"Supposed shape:{(round(len(text_test) / MAX_SEQ_LEN), MAX_SEQ_LEN, N_UNIQUE_CHARS)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fgCNwUaA2TP5"
   },
   "source": [
    "Nice! Now that we got the right output shape from the `vectorize_sentence`, let's vectorize our `sentences`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "gradient": {
     "id": "099a779f-ef31-4aa0-ae84-b8f8fde39dc4",
     "kernelId": ""
    },
    "id": "E4iRZLJL2Fs2",
    "outputId": "e85a57e6-c153-4d93-daf2-2a4627802182"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(736848, 20, 36)\n"
     ]
    }
   ],
   "source": [
    "# vectorize input sentences\n",
    "X_data = vectorize_sentence(sentences);\n",
    "print(X_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FZ436LRL4qPc"
   },
   "source": [
    "> Supposed shape: `(len(sentences), MAX_SEQ_LEN, N_UNIQUE_CHARS)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "gradient": {
     "id": "4d319e9e-6d9a-4261-bf68-74744d8bdec0",
     "kernelId": ""
    },
    "id": "2tHNxwSv2OfG",
    "outputId": "3450ec8e-6359-48e8-b321-69f613a78d8d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(736848, 36)\n"
     ]
    }
   ],
   "source": [
    "# vectorize next_chars (output) -> shape: (m, N_UNIQUE_CHARS)\n",
    "y_data = np.zeros((m, N_UNIQUE_CHARS), dtype=np.bool)\n",
    "for i, char in enumerate(next_chars):\n",
    "    y_data[i, char2int[char]] = 1\n",
    "\n",
    "print(y_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "id": "d40660ab-da06-486a-85cc-48ec25bd610e",
     "kernelId": ""
    },
    "id": "sE7AfpwEW2b4"
   },
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 16\n",
    "\n",
    "def char_LSTM_model(max_seq_len=MAX_SEQ_LEN, max_features=N_UNIQUE_CHARS, embedding_dim=EMBEDDING_DIM):\n",
    "\n",
    "    # Define input for the model (vocab indices)\n",
    "    inputs = tf.keras.Input(shape=(max_seq_len, max_features))\n",
    "\n",
    "    # No embedding for one-hot encoding\n",
    "    # X = Embedding((max_seq_len, max_features), (max_features, embedding_dim))(inputs)\n",
    "\n",
    "    X = LSTM(128, return_sequences=True)(inputs)\n",
    "    X = Flatten()(X)\n",
    "    outputs = Dense(max_features, activation=\"softmax\")(X)\n",
    "    model = Model(inputs, outputs, name=\"model_LSTM\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "gradient": {
     "id": "b72c64b6-3b7d-4380-a9af-22f83a7b148f",
     "kernelId": ""
    },
    "id": "8VglUcNoXeqO",
    "outputId": "606b9285-ee3b-4005-8bcf-692eadddfaa1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-19 04:19:44.628381: W tensorflow/stream_executor/platform/default/dso_loader.cc:65] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2021-11-19 04:19:44.628923: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2021-11-19 04:19:44.629919: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (nwg88xiopd): /proc/driver/nvidia/version does not exist\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_LSTM\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 20, 36)]          0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 20, 128)           84480     \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2560)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 36)                92196     \n",
      "=================================================================\n",
      "Total params: 176,676\n",
      "Trainable params: 176,676\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# let's create our model\n",
    "model = char_LSTM_model()\n",
    "optimizer=tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6q4WasWHJM_B"
   },
   "source": [
    "###  Sampling Functions\n",
    "To pick a word from the model's prediction output, we can either use:\n",
    "1. Greedy search: take the character with the highest probability (argmax). But this will mean that our sampling will be the same.\n",
    "2. Sampling: sampling from the distribution by picking a random character, but with the argmax values being the highest chance to be picked.\n",
    "\n",
    "References:\n",
    "1. https://stackoverflow.com/questions/58764619/why-should-we-use-temperature-in-softmax\n",
    "2. https://datascience.stackexchange.com/questions/72770/why-we-sample-when-predicting-with-recurent-neural-network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "id": "66a4aaae-04d4-4125-81bb-1b04852d33ef",
     "kernelId": ""
    },
    "id": "OeI1aOEbX2Vw"
   },
   "outputs": [],
   "source": [
    "def generate_text(model, original_sentence, step, temperature):\n",
    "    \"\"\"\n",
    "    Generates text from the `model` for `step` number \n",
    "    of times (equivalent to total characters sampled), \n",
    "    given the `original_sentence` (seed) and `temperature` value.\n",
    "\n",
    "    Args:\n",
    "    - model: LSTM model (Keras model)\n",
    "    - original_sentence: text to be used as the starting seed for sampling (str)\n",
    "    - step: number times that you'd want to sample. \n",
    "                ... translates to total chars to be sampled (int)\n",
    "    - temperature: Temperature parameter for softmax function in `sample` (int)\n",
    "    \"\"\"\n",
    "\n",
    "    # get the original sentence\n",
    "    sentence = original_sentence\n",
    "    \n",
    "    print(f\"Generating with this sentence... '{original_sentence}'\")\n",
    "    print(\"Temperature/Diversity value:\", temperature)\n",
    "\n",
    "    generated_sentence = \"\"\n",
    "    for i in range(step):\n",
    "        seed = vectorize_sentence(sentence) # shape-> (1,20,36)\n",
    "        \n",
    "        # get the softmax prediction\n",
    "        predictions=model.predict(seed)[0] # shape -> (20, 36)\n",
    "        \n",
    "        # sample the softmax prediction\n",
    "        next_index = sample(predictions, temperature)\n",
    "\n",
    "        # convert next_index into character\n",
    "        next_char = int2char[next_index]\n",
    "        \n",
    "        # append on our generated sentence\n",
    "        generated_sentence += next_char\n",
    "\n",
    "        # move the \"sentence\" (input) to the right by one char \n",
    "        ## and append the predicted next_char\n",
    "        sentence = sentence[1:] + next_char\n",
    "\n",
    "    print(f\"Generated: {generated_sentence}\")\n",
    "    print()\n",
    "\n",
    "def sample(predictions, temperature=0.2):\n",
    "    \"\"\"\n",
    "    Function to sample from the LSTM Softmax distribution \n",
    "    (as opposed to greedy search - argmax)\n",
    "\n",
    "    Args: \n",
    "    - predictions: LSTM softmax output of shape (MAX_SEQ_LEN, N_UNIQUE_CHARS)\n",
    "    - temperature: temperature parameter for softmax function. \n",
    "                    ... Provides diversity to the sample\n",
    "                    ... the higher the temperature, the less confident the model \n",
    "                           about its pred (int)\n",
    "\n",
    "    Returns:\n",
    "    - max value from the probability distribution of softmax sampling (int) \n",
    "    \"\"\"\n",
    "    # convert into numpy array\n",
    "    predictions = np.asarray(predictions).astype(\"float64\")\n",
    "\n",
    "    # perform softmax sampling\n",
    "    ## the higher the temperature, the less confident the model about its pred\n",
    "    predictions = np.log(predictions) / temperature\n",
    "    exp_preds = np.exp(predictions)\n",
    "    predictions = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, predictions, 1)\n",
    "\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nYXfGrto8JtS"
   },
   "source": [
    "Let's test out our sampling functions to see if they work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "gradient": {
     "id": "d7c64ca4-aa19-48ef-a20a-2944b3602f36",
     "kernelId": ""
    },
    "id": "AnTJ8zDw8OMB",
    "outputId": "092caed4-999c-46ce-a647-88561a0ec508"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46053/46053 [==============================] - 413s 9ms/step - loss: 1.6540 - accuracy: 0.4994\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa692eed510>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH_SIZE = 16\n",
    "\n",
    "# fit only 1 epoch\n",
    "model.fit(x=X_data, y=y_data, batch_size=BATCH_SIZE, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "id": "0838456e-d10a-4c7d-9500-f27de845aecd",
     "kernelId": ""
    },
    "id": "8CViiRyRMC2H"
   },
   "outputs": [],
   "source": [
    "SAMPLING_STEPS = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training from Scratch\n",
    " _start here if you'd like to train from scratch_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "gradient": {
     "id": "428bcb78-e0a4-4bcc-9768-8e8c3a84d7db",
     "kernelId": ""
    },
    "id": "JspPhZ0UK_Jc",
    "outputId": "c21c15e5-b45c-429e-ef29-96362caf90d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating with this sentence... 'h a path but they ne'\n",
      "Temperature/Diversity value: 0.2\n",
      "Generated: ed to the bear for a mind the first and the fell and the wind and the first and the first and the fi\n",
      "\n",
      "\n",
      "Generating with this sentence... 'h a path but they ne'\n",
      "Temperature/Diversity value: 0.5\n",
      "Generated: ar his meas and from his present and the green said frodo should border to leaving the head of the f\n",
      "\n",
      "\n",
      "Generating with this sentence... 'h a path but they ne'\n",
      "Temperature/Diversity value: 1.0\n",
      "Generated: ar are all riladil ight      in the traves apsry the male of that regring at has blokedring to thing\n",
      "\n",
      "\n",
      "Generating with this sentence... 'h a path but they ne'\n",
      "Temperature/Diversity value: 1.2\n",
      "Generated: m take slopp      theses down who had ridill streak i have do heard ano stoking in the darter to the\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def generate_and_sample(model, corpus, sequence_length, step, diversity_list):\n",
    "    \"\"\"\n",
    "    generate & sample characters from model's prediction output\n",
    "\n",
    "    Args:\n",
    "    - model: LSTM model (Keras model)\n",
    "    - corpus: Text to be used as a starting point / seed for sampling (str)\n",
    "    - sequence_length: Maximum sequence length to be for starting point (int)\n",
    "    - step: number times that you'd want to sample. \n",
    "                ... translates to total chars to be sampled (int)\n",
    "    - diversity_list: List of temperature parameters for softmax function \n",
    "                        ... in `sample` (list)\n",
    "\n",
    "    Output:\n",
    "        prints generated text at different diversity/temperature values\n",
    "    \"\"\"\n",
    "\n",
    "    # set a random starting point in the text\n",
    "    start_index = random.randint(0, len(corpus) - sequence_length - 1)\n",
    "\n",
    "    # create a seed\n",
    "    original_sentence = corpus[start_index : start_index + MAX_SEQ_LEN]\n",
    "                                        \n",
    "    for diversity in diversity_list:\n",
    "        generate_text(model, original_sentence, step, diversity)\n",
    "        print()\n",
    "\n",
    "generate_and_sample(model, standardized_text, MAX_SEQ_LEN, SAMPLING_STEPS, [0.2, 0.5, 1.0, 1.2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tquKmXL7MLBv"
   },
   "source": [
    "Of course, our model's prediction output won't make sense it because it's only been trained for 1 epoch, but hey, our sampling functions worked!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "gradient": {
     "id": "df19e572-35e8-4db9-b8f7-0c4c1945bea4",
     "kernelId": ""
    },
    "id": "NSkWhRAM5xQa",
    "outputId": "6bb8efdc-eaf0-462f-9051-a73d07dde414"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------  Epoch: 0/30  ----------------------------------------\n",
      "11513/11514 [============================>.] - ETA: 0s - loss: 1.4689 - accuracy: 0.5494\n",
      "Epoch 00001: saving model to /content/drive/MyDrive/Colab Notebooks/LOTR_LSTM/models/one_hot/model_cp.ckpt\n",
      "11514/11514 [==============================] - 107s 9ms/step - loss: 1.4689 - accuracy: 0.5494\n",
      "\n",
      "****************************** Generating text after epoch #0 ******************************\n",
      "Generating with this sentence... 'feel pleased and tak'\n",
      "Temperature/Diversity value: 0.2\n",
      "Generated: e they were the land of the ring of the ring of the ring of the great down to the door to the warmed\n",
      "\n",
      "\n",
      "Generating with this sentence... 'feel pleased and tak'\n",
      "Temperature/Diversity value: 0.5\n",
      "Generated: en of the far from the grey white the dark in the ring of the ground in the dont they would be the r\n",
      "\n",
      "\n",
      "Generating with this sentence... 'feel pleased and tak'\n",
      "Temperature/Diversity value: 1.0\n",
      "Generated: en they mage of great blied now looked hose let the did not good followirushed greverned round him e\n",
      "\n",
      "\n",
      "Generating with this sentence... 'feel pleased and tak'\n",
      "Temperature/Diversity value: 1.2\n",
      "Generated: es walle forth of saw of held here thongand you knew dogghering his fromoth lordly each i thougl mur\n",
      "\n",
      "\n",
      "----------------------------------------  Epoch: 1/30  ----------------------------------------\n",
      "11511/11514 [============================>.] - ETA: 0s - loss: 1.3770 - accuracy: 0.5739\n",
      "Epoch 00001: saving model to /content/drive/MyDrive/Colab Notebooks/LOTR_LSTM/models/one_hot/model_cp.ckpt\n",
      "11514/11514 [==============================] - 106s 9ms/step - loss: 1.3770 - accuracy: 0.5739\n",
      "\n",
      "****************************** Generating text after epoch #1 ******************************\n",
      "Generating with this sentence... 'ch in pairs by night'\n",
      "Temperature/Diversity value: 0.2\n",
      "Generated:  and the start of the far away and the stream what he said the dark and the start was the dark and t\n",
      "\n",
      "\n",
      "Generating with this sentence... 'ch in pairs by night'\n",
      "Temperature/Diversity value: 0.5\n",
      "Generated:  and the tree the shire and the lands in the twe start and more for a little of the hobbit and with \n",
      "\n",
      "\n",
      "Generating with this sentence... 'ch in pairs by night'\n",
      "Temperature/Diversity value: 1.0\n",
      "Generated:  up as young begind above a little away it out a great dancenty track the dark deep feet a hors als \n",
      "\n",
      "\n",
      "Generating with this sentence... 'ch in pairs by night'\n",
      "Temperature/Diversity value: 1.2\n",
      "Generated:  years rellable at them not birbot wathfur you haltce at least is none zh horsow that i walse clompe\n",
      "\n",
      "\n",
      "----------------------------------------  Epoch: 2/30  ----------------------------------------\n",
      "11514/11514 [==============================] - ETA: 0s - loss: 1.3258 - accuracy: 0.5881\n",
      "Epoch 00001: saving model to /content/drive/MyDrive/Colab Notebooks/LOTR_LSTM/models/one_hot/model_cp.ckpt\n",
      "11514/11514 [==============================] - 107s 9ms/step - loss: 1.3258 - accuracy: 0.5881\n",
      "\n",
      "****************************** Generating text after epoch #2 ******************************\n",
      "Generating with this sentence... ' hear many songs and'\n",
      "Temperature/Diversity value: 0.2\n",
      "Generated:  the stone and the south of the shire and the sun the wind slope and the starting of the land of the\n",
      "\n",
      "\n",
      "Generating with this sentence... ' hear many songs and'\n",
      "Temperature/Diversity value: 0.5\n",
      "Generated:  strange and decided hobbits said the shire of the fire      when he said aragorn but now in the cha\n",
      "\n",
      "\n",
      "Generating with this sentence... ' hear many songs and'\n",
      "Temperature/Diversity value: 1.0\n",
      "Generated:  it glove and smed now you aw out to trough the red of the rivendell is wide his healt sitting my go\n",
      "\n",
      "\n",
      "Generating with this sentence... ' hear many songs and'\n",
      "Temperature/Diversity value: 1.2\n",
      "Generated:  sam of right clears tage and many prise from a mine is clmaking  he walding i reloved off to him sh\n",
      "\n",
      "\n",
      "----------------------------------------  Epoch: 3/30  ----------------------------------------\n",
      "11514/11514 [==============================] - ETA: 0s - loss: 1.2918 - accuracy: 0.5974\n",
      "Epoch 00001: saving model to /content/drive/MyDrive/Colab Notebooks/LOTR_LSTM/models/one_hot/model_cp.ckpt\n",
      "11514/11514 [==============================] - 107s 9ms/step - loss: 1.2918 - accuracy: 0.5974\n",
      "\n",
      "****************************** Generating text after epoch #3 ******************************\n",
      "Generating with this sentence... 'd course passed in a'\n",
      "Temperature/Diversity value: 0.2\n",
      "Generated:  strange the strider some the shire in the shire in the shire in the shire in the shire in the shire\n",
      "\n",
      "\n",
      "Generating with this sentence... 'd course passed in a'\n",
      "Temperature/Diversity value: 0.5\n",
      "Generated: nd the strider and the mist and it was a knee that it was not long again the elven and at last come \n",
      "\n",
      "\n",
      "Generating with this sentence... 'd course passed in a'\n",
      "Temperature/Diversity value: 1.0\n",
      "Generated:  land had heards forties boromir it                 the kinks if a would be begon scorp      this fi\n",
      "\n",
      "\n",
      "Generating with this sentence... 'd course passed in a'\n",
      "Temperature/Diversity value: 1.2\n",
      "Generated:  stanw grey aning  o had seenhes for that that drawh darkerboat jurcknexs it and no set who glow at \n",
      "\n",
      "\n",
      "----------------------------------------  Epoch: 4/30  ----------------------------------------\n",
      "11511/11514 [============================>.] - ETA: 0s - loss: 1.2660 - accuracy: 0.6041\n",
      "Epoch 00001: saving model to /content/drive/MyDrive/Colab Notebooks/LOTR_LSTM/models/one_hot/model_cp.ckpt\n",
      "11514/11514 [==============================] - 107s 9ms/step - loss: 1.2660 - accuracy: 0.6041\n",
      "\n",
      "****************************** Generating text after epoch #4 ******************************\n",
      "Generating with this sentence... 'he in the water     '\n",
      "Temperature/Diversity value: 0.2\n",
      "Generated:                                                                                                     \n",
      "\n",
      "\n",
      "Generating with this sentence... 'he in the water     '\n",
      "Temperature/Diversity value: 0.5\n",
      "Generated:        and the far as the shadows of the bank and the bank of his hand behind with the land of mordo\n",
      "\n",
      "\n",
      "Generating with this sentence... 'he in the water     '\n",
      "Temperature/Diversity value: 1.0\n",
      "Generated:  out fult a red elvenkely readmice a knonger from a heart came to the ofetimely at borders after the\n",
      "\n",
      "\n",
      "Generating with this sentence... 'he in the water     '\n",
      "Temperature/Diversity value: 1.2\n",
      "Generated:  at beyord through given and pippin      the surranded claak and very faraftirying úbleals the daak \n",
      "\n",
      "\n",
      "----------------------------------------  Epoch: 5/30  ----------------------------------------\n",
      "11510/11514 [============================>.] - ETA: 0s - loss: 1.2463 - accuracy: 0.6089\n",
      "Epoch 00001: saving model to /content/drive/MyDrive/Colab Notebooks/LOTR_LSTM/models/one_hot/model_cp.ckpt\n",
      "11514/11514 [==============================] - 108s 9ms/step - loss: 1.2464 - accuracy: 0.6089\n",
      "\n",
      "****************************** Generating text after epoch #5 ******************************\n",
      "Generating with this sentence... 'owed that frodo in s'\n",
      "Temperature/Diversity value: 0.2\n",
      "Generated: ilent and the wall and so they were silent and so they were side of the fear and the doors in the sh\n",
      "\n",
      "\n",
      "Generating with this sentence... 'owed that frodo in s'\n",
      "Temperature/Diversity value: 0.5\n",
      "Generated: ilent            and the wind and the ring      the west of the south and they do not said but it se\n",
      "\n",
      "\n",
      "Generating with this sentence... 'owed that frodo in s'\n",
      "Temperature/Diversity value: 1.0\n",
      "Generated: teep there ancient that they merochment we galadriel afterway as anores westward it to seepiou now t\n",
      "\n",
      "\n",
      "Generating with this sentence... 'owed that frodo in s'\n",
      "Temperature/Diversity value: 1.2\n",
      "Generated: tonelaming uped to his rehiple wept to fond said celebrenels angalthers with this is the white hall \n",
      "\n",
      "\n",
      "----------------------------------------  Epoch: 6/30  ----------------------------------------\n",
      "11511/11514 [============================>.] - ETA: 0s - loss: 1.2300 - accuracy: 0.6131\n",
      "Epoch 00001: saving model to /content/drive/MyDrive/Colab Notebooks/LOTR_LSTM/models/one_hot/model_cp.ckpt\n",
      "11514/11514 [==============================] - 107s 9ms/step - loss: 1.2300 - accuracy: 0.6131\n",
      "\n",
      "****************************** Generating text after epoch #6 ******************************\n",
      "Generating with this sentence... 'the others and all t'\n",
      "Temperature/Diversity value: 0.2\n",
      "Generated: he world and the words of the mountains and the words of the elves and the ring and the mountains an\n",
      "\n",
      "\n",
      "Generating with this sentence... 'the others and all t'\n",
      "Temperature/Diversity value: 0.5\n",
      "Generated: hat defelt he was failing and a few you were not an orcs said gandalf in the door but i should have \n",
      "\n",
      "\n",
      "Generating with this sentence... 'the others and all t'\n",
      "Temperature/Diversity value: 1.0\n",
      "Generated: he marfunds they clanked towards made about shadows by the hisible and denethlacks if shouldn have h\n",
      "\n",
      "\n",
      "Generating with this sentence... 'the others and all t'\n",
      "Temperature/Diversity value: 1.2\n",
      "Generated: hat their shirinaul kelf your bright family with priponeth that gest or imbobbater he happened in ló\n",
      "\n",
      "\n",
      "----------------------------------------  Epoch: 7/30  ----------------------------------------\n",
      "11510/11514 [============================>.] - ETA: 0s - loss: 1.2167 - accuracy: 0.6171\n",
      "Epoch 00001: saving model to /content/drive/MyDrive/Colab Notebooks/LOTR_LSTM/models/one_hot/model_cp.ckpt\n",
      "11514/11514 [==============================] - 108s 9ms/step - loss: 1.2167 - accuracy: 0.6171\n",
      "\n",
      "****************************** Generating text after epoch #7 ******************************\n",
      "Generating with this sentence... ' field where the tre'\n",
      "Temperature/Diversity value: 0.2\n",
      "Generated: es and sam that he stood and a shadow and it was a star in the dark the shadow of the hill before yo\n",
      "\n",
      "\n",
      "Generating with this sentence... ' field where the tre'\n",
      "Temperature/Diversity value: 0.5\n",
      "Generated: es for the ring in the shadow of the hill             and he gave here said merry that is a shadow b\n",
      "\n",
      "\n",
      "Generating with this sentence... ' field where the tre'\n",
      "Temperature/Diversity value: 1.0\n",
      "Generated: es possetsip a two      walk for our trees orow      and rose had come upon this food is out trough \n",
      "\n",
      "\n",
      "Generating with this sentence... ' field where the tre'\n",
      "Temperature/Diversity value: 1.2\n",
      "Generated: es had comes herwimul hear the truef a glitling away easle he had bereforning that springing down bu\n",
      "\n",
      "\n",
      "----------------------------------------  Epoch: 8/30  ----------------------------------------\n",
      "11513/11514 [============================>.] - ETA: 0s - loss: 1.2044 - accuracy: 0.6203\n",
      "Epoch 00001: saving model to /content/drive/MyDrive/Colab Notebooks/LOTR_LSTM/models/one_hot/model_cp.ckpt\n",
      "11514/11514 [==============================] - 108s 9ms/step - loss: 1.2044 - accuracy: 0.6203\n",
      "\n",
      "****************************** Generating text after epoch #8 ******************************\n",
      "Generating with this sentence... 'guess      there is '\n",
      "Temperature/Diversity value: 0.2\n",
      "Generated: a shadow of me a long the shire and the shire and the south and the stream and the shire and the sta\n",
      "\n",
      "\n",
      "Generating with this sentence... 'guess      there is '\n",
      "Temperature/Diversity value: 0.5\n",
      "Generated: shining the stars were a shadow and i shall heard and all has been as they are not all that is the s\n",
      "\n",
      "\n",
      "Generating with this sentence... 'guess      there is '\n",
      "Temperature/Diversity value: 1.0\n",
      "Generated: quickly and frodo slending herslace backly sich of the ground and its no evil only shand bryathters \n",
      "\n",
      "\n",
      "Generating with this sentence... 'guess      there is '\n",
      "Temperature/Diversity value: 1.2\n",
      "Generated: sam its aitrouthron high sturnice of wondered and here put atrembing treering but with him that the \n",
      "\n",
      "\n",
      "----------------------------------------  Epoch: 9/30  ----------------------------------------\n",
      "11509/11514 [============================>.] - ETA: 0s - loss: 1.1943 - accuracy: 0.6229\n",
      "Epoch 00001: saving model to /content/drive/MyDrive/Colab Notebooks/LOTR_LSTM/models/one_hot/model_cp.ckpt\n",
      "11514/11514 [==============================] - 108s 9ms/step - loss: 1.1944 - accuracy: 0.6229\n",
      "\n",
      "****************************** Generating text after epoch #9 ******************************\n",
      "Generating with this sentence... 'n at them with his f'\n",
      "Temperature/Diversity value: 0.2\n",
      "Generated: ingers and the songs of the shire and the grey something the sight of the dark they were see the dar\n",
      "\n",
      "\n",
      "Generating with this sentence... 'n at them with his f'\n",
      "Temperature/Diversity value: 0.5\n",
      "Generated: ace was a great do you not know what it was still for some was as if he was the days of the land who\n",
      "\n",
      "\n",
      "Generating with this sentence... 'n at them with his f'\n",
      "Temperature/Diversity value: 1.0\n",
      "Generated: irst biff came it and though the tall he woveming ebie as that a mist of the new of stringer often t\n",
      "\n",
      "\n",
      "Generating with this sentence... 'n at them with his f'\n",
      "Temperature/Diversity value: 1.2\n",
      "Generated: aces and in the night of cry of larged and filled we should gem herewyey hilt i will for thousands o\n",
      "\n",
      "\n",
      "----------------------------------------  Epoch: 10/30  ----------------------------------------\n",
      "11509/11514 [============================>.] - ETA: 0s - loss: 1.1855 - accuracy: 0.6250\n",
      "Epoch 00001: saving model to /content/drive/MyDrive/Colab Notebooks/LOTR_LSTM/models/one_hot/model_cp.ckpt\n",
      "11514/11514 [==============================] - 108s 9ms/step - loss: 1.1855 - accuracy: 0.6250\n",
      "\n",
      "****************************** Generating text after epoch #10 ******************************\n",
      "Generating with this sentence... 'h an answer not even'\n",
      "Temperature/Diversity value: 0.2\n",
      "Generated:  as the shire                                                                                       \n",
      "\n",
      "\n",
      "Generating with this sentence... 'h an answer not even'\n",
      "Temperature/Diversity value: 0.5\n",
      "Generated:  the work of the shire and from the hill and some was a sound of sharp and it was an end of aragorn \n",
      "\n",
      "\n",
      "Generating with this sentence... 'h an answer not even'\n",
      "Temperature/Diversity value: 1.0\n",
      "Generated:  is the elvisafies to do merry was long field the side feeling companions with do there was restion \n",
      "\n",
      "\n",
      "Generating with this sentence... 'h an answer not even'\n",
      "Temperature/Diversity value: 1.2\n",
      "Generated:  towards you cant gallong too such adventure and went all the lanted frodo before only reffict of ar\n",
      "\n",
      "\n",
      "----------------------------------------  Epoch: 11/30  ----------------------------------------\n",
      "11509/11514 [============================>.] - ETA: 0s - loss: 1.1774 - accuracy: 0.6274\n",
      "Epoch 00001: saving model to /content/drive/MyDrive/Colab Notebooks/LOTR_LSTM/models/one_hot/model_cp.ckpt\n",
      "11514/11514 [==============================] - 108s 9ms/step - loss: 1.1774 - accuracy: 0.6274\n",
      "\n",
      "****************************** Generating text after epoch #11 ******************************\n",
      "Generating with this sentence... ' there came into vie'\n",
      "Temperature/Diversity value: 0.2\n",
      "Generated: w and sam said gandalf and he said i have been the stars of the chamber and the bank the window and \n",
      "\n",
      "\n",
      "Generating with this sentence... ' there came into vie'\n",
      "Temperature/Diversity value: 0.5\n",
      "Generated: w              there were for a long all the shire were above the road a shape of dark light of the \n",
      "\n",
      "\n",
      "Generating with this sentence... ' there came into vie'\n",
      "Temperature/Diversity value: 1.0\n",
      "Generated: wed stiff above in heard now behind than he heard aragornges delitile line in the polishead is the h\n",
      "\n",
      "\n",
      "Generating with this sentence... ' there came into vie'\n",
      "Temperature/Diversity value: 1.2\n",
      "Generated: whols such tes and heap long againg at line of the black yard they are heaps of the hills meat said \n",
      "\n",
      "\n",
      "----------------------------------------  Epoch: 12/30  ----------------------------------------\n",
      "11511/11514 [============================>.] - ETA: 0s - loss: 1.1704 - accuracy: 0.6289\n",
      "Epoch 00001: saving model to /content/drive/MyDrive/Colab Notebooks/LOTR_LSTM/models/one_hot/model_cp.ckpt\n",
      "11514/11514 [==============================] - 109s 9ms/step - loss: 1.1704 - accuracy: 0.6289\n",
      "\n",
      "****************************** Generating text after epoch #12 ******************************\n",
      "Generating with this sentence... 'chengarden grey with'\n",
      "Temperature/Diversity value: 0.2\n",
      "Generated:  the shire there was a shadow and the land of the shire and he was heard the shire there was a shado\n",
      "\n",
      "\n",
      "Generating with this sentence... 'chengarden grey with'\n",
      "Temperature/Diversity value: 0.5\n",
      "Generated:  a shadow and he drew his head and there and all that i had something to the shire remained still al\n",
      "\n",
      "\n",
      "Generating with this sentence... 'chengarden grey with'\n",
      "Temperature/Diversity value: 1.0\n",
      "Generated:  mostly in its reas be weary but verity but said gandalf all raised in wit said pippin and died a fi\n",
      "\n",
      "\n",
      "Generating with this sentence... 'chengarden grey with'\n",
      "Temperature/Diversity value: 1.2\n",
      "Generated: in sounds sam at hand glimprent wallshep which he had not beyone hands he will be us they knew that \n",
      "\n",
      "\n",
      "----------------------------------------  Epoch: 13/30  ----------------------------------------\n",
      "11514/11514 [==============================] - ETA: 0s - loss: 1.1641 - accuracy: 0.6311\n",
      "Epoch 00001: saving model to /content/drive/MyDrive/Colab Notebooks/LOTR_LSTM/models/one_hot/model_cp.ckpt\n",
      "11514/11514 [==============================] - 109s 9ms/step - loss: 1.1641 - accuracy: 0.6311\n",
      "\n",
      "****************************** Generating text after epoch #13 ******************************\n",
      "Generating with this sentence... '      the breaking o'\n",
      "Temperature/Diversity value: 0.2\n",
      "Generated: n the shadow and the ring was not and the business of the shadow and the stream the great roots and \n",
      "\n",
      "\n",
      "Generating with this sentence... '      the breaking o'\n",
      "Temperature/Diversity value: 0.5\n",
      "Generated: n a court of the shadow in the shire and the water seemed to faramir then speaking the mirror and st\n",
      "\n",
      "\n",
      "Generating with this sentence... '      the breaking o'\n",
      "Temperature/Diversity value: 1.0\n",
      "Generated: f isforthtrongel used that i have not go ounsel all you seem sam      noiced to dance      when they\n",
      "\n",
      "\n",
      "Generating with this sentence... '      the breaking o'\n",
      "Temperature/Diversity value: 1.2\n",
      "Generated: nce it was héoked and liet us but far at any rose i see sook the me in hobbitts of things or telling\n",
      "\n",
      "\n",
      "----------------------------------------  Epoch: 14/30  ----------------------------------------\n",
      "11510/11514 [============================>.] - ETA: 0s - loss: 1.1581 - accuracy: 0.6326\n",
      "Epoch 00001: saving model to /content/drive/MyDrive/Colab Notebooks/LOTR_LSTM/models/one_hot/model_cp.ckpt\n",
      "11514/11514 [==============================] - 109s 10ms/step - loss: 1.1581 - accuracy: 0.6326\n",
      "\n",
      "****************************** Generating text after epoch #14 ******************************\n",
      "Generating with this sentence... 'ng him with an easy '\n",
      "Temperature/Diversity value: 0.2\n",
      "Generated: the southward the bottom the sun was still the land of the water and the southward and the southward\n",
      "\n",
      "\n",
      "Generating with this sentence... 'ng him with an easy '\n",
      "Temperature/Diversity value: 0.5\n",
      "Generated: in the same to be merry is a country and the bring what they were become of the east who were some a\n",
      "\n",
      "\n",
      "Generating with this sentence... 'ng him with an easy '\n",
      "Temperature/Diversity value: 1.0\n",
      "Generated: though for long either he tongue      who is ill crall and went off      maybe they as long and stor\n",
      "\n",
      "\n",
      "Generating with this sentence... 'ng him with an easy '\n",
      "Temperature/Diversity value: 1.2\n",
      "Generated: at once its            son of it you would and thousale ringle but moving all than asiculs bad flywe\n",
      "\n",
      "\n",
      "----------------------------------------  Epoch: 15/30  ----------------------------------------\n",
      "11512/11514 [============================>.] - ETA: 0s - loss: 1.1528 - accuracy: 0.6337\n",
      "Epoch 00001: saving model to /content/drive/MyDrive/Colab Notebooks/LOTR_LSTM/models/one_hot/model_cp.ckpt\n",
      "11514/11514 [==============================] - 110s 10ms/step - loss: 1.1528 - accuracy: 0.6337\n",
      "\n",
      "****************************** Generating text after epoch #15 ******************************\n",
      "Generating with this sentence... 'multiply      seldom'\n",
      "Temperature/Diversity value: 0.2\n",
      "Generated:  right and the three the shadow and the land were for a while the land were strange the shire in the\n",
      "\n",
      "\n",
      "Generating with this sentence... 'multiply      seldom'\n",
      "Temperature/Diversity value: 0.5\n",
      "Generated:  the sword of the bank he sprang forbidd and to flow and spearing all the red bart and the stream th\n",
      "\n",
      "\n",
      "Generating with this sentence... 'multiply      seldom'\n",
      "Temperature/Diversity value: 1.0\n",
      "Generated:  lughuabing the black roof uswit the race of the road for isengard of these could heard in pippin em\n",
      "\n",
      "\n",
      "Generating with this sentence... 'multiply      seldom'\n",
      "Temperature/Diversity value: 1.2\n",
      "Generated:  take any rising and began a chair we lie he was riten ejgent great bees on toward tooking the open \n",
      "\n",
      "\n",
      "----------------------------------------  Epoch: 16/30  ----------------------------------------\n",
      "11509/11514 [============================>.] - ETA: 0s - loss: 1.1480 - accuracy: 0.6351\n",
      "Epoch 00001: saving model to /content/drive/MyDrive/Colab Notebooks/LOTR_LSTM/models/one_hot/model_cp.ckpt\n",
      "11514/11514 [==============================] - 110s 10ms/step - loss: 1.1480 - accuracy: 0.6351\n",
      "\n",
      "****************************** Generating text after epoch #16 ******************************\n",
      "Generating with this sentence... 'came from amon dn to'\n",
      "Temperature/Diversity value: 0.2\n",
      "Generated: k go at the forest of the end of the misty mountains and the shire and the trees and the way to the \n",
      "\n",
      "\n",
      "Generating with this sentence... 'came from amon dn to'\n",
      "Temperature/Diversity value: 0.5\n",
      "Generated:  the sunlent hand the hall of the others followed in the end of the chamber and then the edges of th\n",
      "\n",
      "\n",
      "Generating with this sentence... 'came from amon dn to'\n",
      "Temperature/Diversity value: 1.0\n",
      "Generated: k any voice of the moblisaed and grey tells some of old barre still side piegareanies i have a fall \n",
      "\n",
      "\n",
      "Generating with this sentence... 'came from amon dn to'\n",
      "Temperature/Diversity value: 1.2\n",
      "Generated: kgell tharbas and far as methom as easy road again it runsayesworessal satuy an opening behath she l\n",
      "\n",
      "\n",
      "----------------------------------------  Epoch: 17/30  ----------------------------------------\n",
      "11514/11514 [==============================] - ETA: 0s - loss: 1.1427 - accuracy: 0.6367\n",
      "Epoch 00001: saving model to /content/drive/MyDrive/Colab Notebooks/LOTR_LSTM/models/one_hot/model_cp.ckpt\n",
      "11514/11514 [==============================] - 110s 10ms/step - loss: 1.1427 - accuracy: 0.6367\n",
      "\n",
      "****************************** Generating text after epoch #17 ******************************\n",
      "Generating with this sentence... 'of man or beast has '\n",
      "Temperature/Diversity value: 0.2\n",
      "Generated: been distance of the ring was not and the shadow of the wind but the shadow and the ring was not as \n",
      "\n",
      "\n",
      "Generating with this sentence... 'of man or beast has '\n",
      "Temperature/Diversity value: 0.5\n",
      "Generated: dare who were with the door and the four a few narrow of the driven but the company sam shown had le\n",
      "\n",
      "\n",
      "Generating with this sentence... 'of man or beast has '\n",
      "Temperature/Diversity value: 1.0\n",
      "Generated: gandalf were bare now in and fiest and lights with gandalf was one even used more to weecheard about\n",
      "\n",
      "\n",
      "Generating with this sentence... 'of man or beast has '\n",
      "Temperature/Diversity value: 1.2\n",
      "Generated: ferry hader of elrond beforch it bore to fields      clave on his head as puthing from my owruisied \n",
      "\n",
      "\n",
      "----------------------------------------  Epoch: 18/30  ----------------------------------------\n",
      "11509/11514 [============================>.] - ETA: 0s - loss: 1.1389 - accuracy: 0.6375\n",
      "Epoch 00001: saving model to /content/drive/MyDrive/Colab Notebooks/LOTR_LSTM/models/one_hot/model_cp.ckpt\n",
      "11514/11514 [==============================] - 111s 10ms/step - loss: 1.1389 - accuracy: 0.6375\n",
      "\n",
      "****************************** Generating text after epoch #18 ******************************\n",
      "Generating with this sentence... 'ack that gandalf bil'\n",
      "Temperature/Diversity value: 0.2\n",
      "Generated: bo and the sea the forest windows of the ring had not been as they were the strength and the tree th\n",
      "\n",
      "\n",
      "Generating with this sentence... 'ack that gandalf bil'\n",
      "Temperature/Diversity value: 0.5\n",
      "Generated: l far below them into the hobbits of the shire and there were all the windows was the shadow of the \n",
      "\n",
      "\n",
      "Generating with this sentence... 'ack that gandalf bil'\n",
      "Temperature/Diversity value: 1.0\n",
      "Generated: bo wish tigltentand very counsel rate passed and under the men of specially than the ladd must beman\n",
      "\n",
      "\n",
      "Generating with this sentence... 'ack that gandalf bil'\n",
      "Temperature/Diversity value: 1.2\n",
      "Generated: bo alone end of the green tier that lovetod a bals i supposer than sofless of thom mordor elbarlion \n",
      "\n",
      "\n",
      "----------------------------------------  Epoch: 19/30  ----------------------------------------\n",
      "11509/11514 [============================>.] - ETA: 0s - loss: 1.1345 - accuracy: 0.6390\n",
      "Epoch 00001: saving model to /content/drive/MyDrive/Colab Notebooks/LOTR_LSTM/models/one_hot/model_cp.ckpt\n",
      "11514/11514 [==============================] - 111s 10ms/step - loss: 1.1345 - accuracy: 0.6390\n",
      "\n",
      "****************************** Generating text after epoch #19 ******************************\n",
      "Generating with this sentence... 'een built a wooden p'\n",
      "Temperature/Diversity value: 0.2\n",
      "Generated: ass of the shadow and some blood a long water and many things of the shire and strange the shire of \n",
      "\n",
      "\n",
      "Generating with this sentence... 'een built a wooden p'\n",
      "Temperature/Diversity value: 0.5\n",
      "Generated: lace in sam stooped and the shire lies the lesser       the shire and there were some of the shireho\n",
      "\n",
      "\n",
      "Generating with this sentence... 'een built a wooden p'\n",
      "Temperature/Diversity value: 1.0\n",
      "Generated: art at the dark shouldch boraddy brey and i had become lower            no longer said but their fla\n",
      "\n",
      "\n",
      "Generating with this sentence... 'een built a wooden p'\n",
      "Temperature/Diversity value: 1.2\n",
      "Generated: lace       this pauses pruded downfortagely as standand but i will keep alls well hes sign outwander\n",
      "\n",
      "\n",
      "----------------------------------------  Epoch: 20/30  ----------------------------------------\n",
      "11510/11514 [============================>.] - ETA: 0s - loss: 1.1311 - accuracy: 0.6394\n",
      "Epoch 00001: saving model to /content/drive/MyDrive/Colab Notebooks/LOTR_LSTM/models/one_hot/model_cp.ckpt\n",
      "11514/11514 [==============================] - 111s 10ms/step - loss: 1.1311 - accuracy: 0.6394\n",
      "\n",
      "****************************** Generating text after epoch #20 ******************************\n",
      "Generating with this sentence... 'r lunch but pippin r'\n",
      "Temperature/Diversity value: 0.2\n",
      "Generated: an there was a little began to see in the end of the end of the river and the stars and the mountain\n",
      "\n",
      "\n",
      "Generating with this sentence... 'r lunch but pippin r'\n",
      "Temperature/Diversity value: 0.5\n",
      "Generated: an there was all the trees the ring and now the wind he was an ancient with for you will see i am so\n",
      "\n",
      "\n",
      "Generating with this sentence... 'r lunch but pippin r'\n",
      "Temperature/Diversity value: 1.0\n",
      "Generated: eturned thed until it is it glimpse of may one dominded we never got for the houses land was still a\n",
      "\n",
      "\n",
      "Generating with this sentence... 'r lunch but pippin r'\n",
      "Temperature/Diversity value: 1.2\n",
      "Generated: ance he went on them like would nat loft turn in a teels mean but over him fear in here an our  i di\n",
      "\n",
      "\n",
      "----------------------------------------  Epoch: 21/30  ----------------------------------------\n",
      "11514/11514 [==============================] - ETA: 0s - loss: 1.1271 - accuracy: 0.6409\n",
      "Epoch 00001: saving model to /content/drive/MyDrive/Colab Notebooks/LOTR_LSTM/models/one_hot/model_cp.ckpt\n",
      "11514/11514 [==============================] - 111s 10ms/step - loss: 1.1271 - accuracy: 0.6409\n",
      "\n",
      "****************************** Generating text after epoch #21 ******************************\n",
      "Generating with this sentence... 'ck and his dark hair'\n",
      "Temperature/Diversity value: 0.2\n",
      "Generated:  and stone where the shire and the stream      i dont think you have had been the high stars and the\n",
      "\n",
      "\n",
      "Generating with this sentence... 'ck and his dark hair'\n",
      "Temperature/Diversity value: 0.5\n",
      "Generated:  and they had just the water to hear him some way      frodo was like a great disquiet in the shire \n",
      "\n",
      "\n",
      "Generating with this sentence... 'ck and his dark hair'\n",
      "Temperature/Diversity value: 1.0\n",
      "Generated:       he has his brandy was with silon six only lights and scup of his precioud crept and men pierce\n",
      "\n",
      "\n",
      "Generating with this sentence... 'ck and his dark hair'\n",
      "Temperature/Diversity value: 1.2\n",
      "Generated:  and home then way he drew up them two chongers though their paught figrywimpssed to tell it hills f\n",
      "\n",
      "\n",
      "----------------------------------------  Epoch: 22/30  ----------------------------------------\n",
      "11513/11514 [============================>.] - ETA: 0s - loss: 1.1237 - accuracy: 0.6418\n",
      "Epoch 00001: saving model to /content/drive/MyDrive/Colab Notebooks/LOTR_LSTM/models/one_hot/model_cp.ckpt\n",
      "11514/11514 [==============================] - 112s 10ms/step - loss: 1.1237 - accuracy: 0.6418\n",
      "\n",
      "****************************** Generating text after epoch #22 ******************************\n",
      "Generating with this sentence... ' inns make longer on'\n",
      "Temperature/Diversity value: 0.2\n",
      "Generated:  the three they were all the south and the stars and the mountains and the shadow of the country of \n",
      "\n",
      "\n",
      "Generating with this sentence... ' inns make longer on'\n",
      "Temperature/Diversity value: 0.5\n",
      "Generated:  the stars and the trees and the hall of the wind had drained and the world of the long the others s\n",
      "\n",
      "\n",
      "Generating with this sentence... ' inns make longer on'\n",
      "Temperature/Diversity value: 1.0\n",
      "Generated:  the arms lobelis alone her falls then fallons and maybe watched but they came upon him now     o th\n",
      "\n",
      "\n",
      "Generating with this sentence... ' inns make longer on'\n",
      "Temperature/Diversity value: 1.2\n",
      "Generated:  its glory the branthounded broken hillt in the darkened on deflauft so for these lire where the bin\n",
      "\n",
      "\n",
      "----------------------------------------  Epoch: 23/30  ----------------------------------------\n",
      "11513/11514 [============================>.] - ETA: 0s - loss: 1.1206 - accuracy: 0.6427\n",
      "Epoch 00001: saving model to /content/drive/MyDrive/Colab Notebooks/LOTR_LSTM/models/one_hot/model_cp.ckpt\n",
      "11514/11514 [==============================] - 112s 10ms/step - loss: 1.1206 - accuracy: 0.6427\n",
      "\n",
      "****************************** Generating text after epoch #23 ******************************\n",
      "Generating with this sentence... ' a chance to cut our'\n",
      "Temperature/Diversity value: 0.2\n",
      "Generated:  way                                                                                                \n",
      "\n",
      "\n",
      "Generating with this sentence... ' a chance to cut our'\n",
      "Temperature/Diversity value: 0.5\n",
      "Generated:  way      i will see why could see him as if he was a dark black shape of the elves side            \n",
      "\n",
      "\n",
      "Generating with this sentence... ' a chance to cut our'\n",
      "Temperature/Diversity value: 1.0\n",
      "Generated:  case different tranide is going said frodo in arrows they seemed to his first above again pippin wh\n",
      "\n",
      "\n",
      "Generating with this sentence... ' a chance to cut our'\n",
      "Temperature/Diversity value: 1.2\n",
      "Generated:  life then almost to be seen a saurvastly body tunscest could will hand a cull unless he made of giv\n",
      "\n",
      "\n",
      "----------------------------------------  Epoch: 24/30  ----------------------------------------\n",
      "11512/11514 [============================>.] - ETA: 0s - loss: 1.1178 - accuracy: 0.6434\n",
      "Epoch 00001: saving model to /content/drive/MyDrive/Colab Notebooks/LOTR_LSTM/models/one_hot/model_cp.ckpt\n",
      "11514/11514 [==============================] - 112s 10ms/step - loss: 1.1178 - accuracy: 0.6434\n",
      "\n",
      "****************************** Generating text after epoch #24 ******************************\n",
      "Generating with this sentence... 'er walls and fences '\n",
      "Temperature/Diversity value: 0.2\n",
      "Generated: and the fire was still door that i have been to the road and the shire and the ground and a shadow o\n",
      "\n",
      "\n",
      "Generating with this sentence... 'er walls and fences '\n",
      "Temperature/Diversity value: 0.5\n",
      "Generated: of the shire and the lands of the elderlded to the brandybuck and he looked at him and hoped in the \n",
      "\n",
      "\n",
      "Generating with this sentence... 'er walls and fences '\n",
      "Temperature/Diversity value: 1.0\n",
      "Generated: and took it him for good or said aragorns be a flash and presentry of darkners that is afraid was be\n",
      "\n",
      "\n",
      "Generating with this sentence... 'er walls and fences '\n",
      "Temperature/Diversity value: 1.2\n",
      "Generated: of arwent in the truth came into hiddenless and had seazed the shire he said to live at all other wi\n",
      "\n",
      "\n",
      "----------------------------------------  Epoch: 25/30  ----------------------------------------\n",
      "11512/11514 [============================>.] - ETA: 0s - loss: 1.1149 - accuracy: 0.6442\n",
      "Epoch 00001: saving model to /content/drive/MyDrive/Colab Notebooks/LOTR_LSTM/models/one_hot/model_cp.ckpt\n",
      "11514/11514 [==============================] - 112s 10ms/step - loss: 1.1149 - accuracy: 0.6442\n",
      "\n",
      "****************************** Generating text after epoch #25 ******************************\n",
      "Generating with this sentence... 'nd its fires went ou'\n",
      "Temperature/Diversity value: 0.2\n",
      "Generated: t of the shadow when they were some of the shire were stone the ship to the great ship road there wa\n",
      "\n",
      "\n",
      "Generating with this sentence... 'nd its fires went ou'\n",
      "Temperature/Diversity value: 0.5\n",
      "Generated: t of his eyes he said and he said to his face      there was a letter looked away on the shire but t\n",
      "\n",
      "\n",
      "Generating with this sentence... 'nd its fires went ou'\n",
      "Temperature/Diversity value: 1.0\n",
      "Generated: t it then whem thus in the sky food and they saw the stars and thus that sighing and fevarthelves of\n",
      "\n",
      "\n",
      "Generating with this sentence... 'nd its fires went ou'\n",
      "Temperature/Diversity value: 1.2\n",
      "Generated: t untruince staught in one of the lor several beyond it as much underding to crownthief theres some \n",
      "\n",
      "\n",
      "----------------------------------------  Epoch: 26/30  ----------------------------------------\n",
      "11510/11514 [============================>.] - ETA: 0s - loss: 1.1122 - accuracy: 0.6451\n",
      "Epoch 00001: saving model to /content/drive/MyDrive/Colab Notebooks/LOTR_LSTM/models/one_hot/model_cp.ckpt\n",
      "11514/11514 [==============================] - 113s 10ms/step - loss: 1.1123 - accuracy: 0.6451\n",
      "\n",
      "****************************** Generating text after epoch #26 ******************************\n",
      "Generating with this sentence... 'nt i thought you wer'\n",
      "Temperature/Diversity value: 0.2\n",
      "Generated: e said but i will go to make a house if you do not be i have not been the long the shadow but the ri\n",
      "\n",
      "\n",
      "Generating with this sentence... 'nt i thought you wer'\n",
      "Temperature/Diversity value: 0.5\n",
      "Generated: e in the later back the country of his and the ending and then the green the fellow has become of th\n",
      "\n",
      "\n",
      "Generating with this sentence... 'nt i thought you wer'\n",
      "Temperature/Diversity value: 1.0\n",
      "Generated: e almost as i know and happy my carvs and disaty      you can say do some will chapters      the mar\n",
      "\n",
      "\n",
      "Generating with this sentence... 'nt i thought you wer'\n",
      "Temperature/Diversity value: 1.2\n",
      "Generated: e order and firesliey now you not weak at fully crossing one  and the star no more  no set though hi\n",
      "\n",
      "\n",
      "----------------------------------------  Epoch: 27/30  ----------------------------------------\n",
      "11509/11514 [============================>.] - ETA: 0s - loss: 1.1095 - accuracy: 0.6453\n",
      "Epoch 00001: saving model to /content/drive/MyDrive/Colab Notebooks/LOTR_LSTM/models/one_hot/model_cp.ckpt\n",
      "11514/11514 [==============================] - 113s 10ms/step - loss: 1.1095 - accuracy: 0.6453\n",
      "\n",
      "****************************** Generating text after epoch #27 ******************************\n",
      "Generating with this sentence... 'ndor hear now the st'\n",
      "Temperature/Diversity value: 0.2\n",
      "Generated: ars and the stars were not a fair many way if you have come to the things that the shire they had se\n",
      "\n",
      "\n",
      "Generating with this sentence... 'ndor hear now the st'\n",
      "Temperature/Diversity value: 0.5\n",
      "Generated: one would be a brief well i am a night behind the road there was a brief and with his heads and the \n",
      "\n",
      "\n",
      "Generating with this sentence... 'ndor hear now the st'\n",
      "Temperature/Diversity value: 1.0\n",
      "Generated: air and the woods there was and with gollum you have so dares a long rumble seem of it or that yet h\n",
      "\n",
      "\n",
      "Generating with this sentence... 'ndor hear now the st'\n",
      "Temperature/Diversity value: 1.2\n",
      "Generated: reetconsemon had been turned from circuckable lúthien went went down towards holding as if its paths\n",
      "\n",
      "\n",
      "----------------------------------------  Epoch: 28/30  ----------------------------------------\n",
      "11512/11514 [============================>.] - ETA: 0s - loss: 1.1070 - accuracy: 0.6464\n",
      "Epoch 00001: saving model to /content/drive/MyDrive/Colab Notebooks/LOTR_LSTM/models/one_hot/model_cp.ckpt\n",
      "11514/11514 [==============================] - 114s 10ms/step - loss: 1.1070 - accuracy: 0.6464\n",
      "\n",
      "****************************** Generating text after epoch #28 ******************************\n",
      "Generating with this sentence... 'ater yet frodo began'\n",
      "Temperature/Diversity value: 0.2\n",
      "Generated:  to see the companions with a deep road and the wind of the bank and the world of the peril was a sh\n",
      "\n",
      "\n",
      "Generating with this sentence... 'ater yet frodo began'\n",
      "Temperature/Diversity value: 0.5\n",
      "Generated:  to make other remained said strider when the brand i think of the water at the bow who were you can\n",
      "\n",
      "\n",
      "Generating with this sentence... 'ater yet frodo began'\n",
      "Temperature/Diversity value: 1.0\n",
      "Generated:  to make on the waters the pavish of them gold and of rainier the shire they stood his road which we\n",
      "\n",
      "\n",
      "Generating with this sentence... 'ater yet frodo began'\n",
      "Temperature/Diversity value: 1.2\n",
      "Generated:  to vhincle my streadly if you denethor a rockylion      you frodo bill arisent son esswaset still d\n",
      "\n",
      "\n",
      "----------------------------------------  Epoch: 29/30  ----------------------------------------\n",
      "11510/11514 [============================>.] - ETA: 0s - loss: 1.1045 - accuracy: 0.6471\n",
      "Epoch 00001: saving model to /content/drive/MyDrive/Colab Notebooks/LOTR_LSTM/models/one_hot/model_cp.ckpt\n",
      "11514/11514 [==============================] - 115s 10ms/step - loss: 1.1045 - accuracy: 0.6471\n",
      "\n",
      "****************************** Generating text after epoch #29 ******************************\n",
      "Generating with this sentence... 'ack riders would hav'\n",
      "Temperature/Diversity value: 0.2\n",
      "Generated: e seen by the black lasted and the stream that is the party and the wind but the walls of gold the g\n",
      "\n",
      "\n",
      "Generating with this sentence... 'ack riders would hav'\n",
      "Temperature/Diversity value: 0.5\n",
      "Generated: e seen in the shadow and went to go and the sea the world with the door does not him the light of th\n",
      "\n",
      "\n",
      "Generating with this sentence... 'ack riders would hav'\n",
      "Temperature/Diversity value: 1.0\n",
      "Generated: e you and till you my mealy of galadriel into a march by the feet of his finger side but behind here\n",
      "\n",
      "\n",
      "Generating with this sentence... 'ack riders would hav'\n",
      "Temperature/Diversity value: 1.2\n",
      "Generated: e demand an end éomyt is eyes and nearer upon the story and under the fled frodo lost far fastecella\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a callback that saves the model's weights\n",
    "checkpoint_path = path / \"models/one_hot/model_cp.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path, \n",
    "                                                 save_weights_only=True, \n",
    "                                                 verbose=1)\n",
    "\n",
    "# Train the model\n",
    "epochs = 30\n",
    "BATCH_SIZE = 64\n",
    "SAMPLING_STEPS = 100\n",
    "diversity_list = [0.2, 0.5, 1.0, 1.2]\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(\"-\"*40 + f\"  Epoch: {epoch}/{epochs}  \" + \"-\"*40)\n",
    "    model.fit(X_data, y_data, batch_size=BATCH_SIZE, epochs=1, callbacks=[cp_callback])\n",
    "    print()\n",
    "    print(\"*\"*30 + f\" Generating text after epoch #{epoch} \" + \"*\"*30)\n",
    "    generate_and_sample(model, standardized_text, MAX_SEQ_LEN, SAMPLING_STEPS, \n",
    "                        diversity_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "id": "ad1a71e6-6418-4bd3-bb2d-cfe0dde37176",
     "kernelId": ""
    },
    "id": "rq68WrcQYDyh"
   },
   "outputs": [],
   "source": [
    "model.save(path / \"models/Char_LSTM_LOTR_OneHot.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Saved Model \n",
    "_Start here if you'd like to use the saved model_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "id": "a9d4aa50-ffe9-4735-9b6a-f20121fdeb46",
     "kernelId": ""
    },
    "id": "1jRj-VpENVPv"
   },
   "outputs": [],
   "source": [
    "model = load_model(path / \"models/Char_LSTM_LOTR_OneHot.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "gradient": {
     "id": "e009cd9a-e35b-4568-9b99-9cb3c1bf2399",
     "kernelId": ""
    },
    "id": "41ddr6Ikw1BM",
    "outputId": "b8ea2b70-031d-4c56-85e5-a039b99d53aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23027/23027 [==============================] - 115s 5ms/step - loss: 1.0686 - accuracy: 0.6575\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.0685958862304688, 0.6575263738632202]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.evaluate(X_data, y_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1vtjx6ip_ASf"
   },
   "source": [
    "### Test out different learning rates\n",
    "\n",
    "Let's test out different learning rates on the model to see if we can squeeze better accuracy than 0.64 - 0.66\n",
    "\n",
    "Using the equation:\n",
    "$1e^{-3} \\times 1000^{\\frac{epoch}{total\\_epoch}}$\n",
    "\n",
    "we should get the following range:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "gradient": {
     "id": "4beac8ca-c860-45d9-a214-187e499e354e",
     "kernelId": ""
    },
    "id": "w-grF12wEI6s",
    "outputId": "1beb1db5-7b09-4809-d7f5-63345c5e6a92"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** Epoch: 0 ********************\n",
      "0.001\n",
      "******************** Epoch: 1 ********************\n",
      "0.00199526231496888\n",
      "******************** Epoch: 2 ********************\n",
      "0.0039810717055349725\n",
      "******************** Epoch: 3 ********************\n",
      "0.007943282347242814\n",
      "******************** Epoch: 4 ********************\n",
      "0.015848931924611138\n",
      "******************** Epoch: 5 ********************\n",
      "0.03162277660168379\n",
      "******************** Epoch: 6 ********************\n",
      "0.06309573444801932\n",
      "******************** Epoch: 7 ********************\n",
      "0.12589254117941667\n",
      "******************** Epoch: 8 ********************\n",
      "0.25118864315095807\n",
      "******************** Epoch: 9 ********************\n",
      "0.5011872336272724\n",
      "******************** Epoch: 10 ********************\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "total_epochs = 10\n",
    "\n",
    "for i in range(total_epochs + 1):\n",
    "    print(\"*\"*20 + f\" Epoch: {i} \" + \"*\"*20)\n",
    "    print(1e-3 * 1000 ** (i/total_epochs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SNdulE5FGhJS"
   },
   "source": [
    "Let's train our model for another 10 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "id": "33983fd4-1248-4a53-b3a0-cefd1b906f99",
     "kernelId": ""
    }
   },
   "outputs": [],
   "source": [
    "# class GenerateSampleCallback(tf.keras.callbacks.Callback):\n",
    "#     \"\"\"\n",
    "#     generate & sample characters from model's prediction output\n",
    "\n",
    "#     Args:\n",
    "#     - corpus: Text to be used as a starting point / seed for sampling (str)\n",
    "#     - sequence_length: Maximum sequence length to be for starting point (int)\n",
    "#     - step: number times that you'd want to sample. \n",
    "#                 ... translates to total chars to be sampled (int)\n",
    "#     - diversity_list: List of temperature parameters for softmax function \n",
    "#                         ... in `sample` (list)\n",
    "\n",
    "#     Output:\n",
    "#         generates text at different diversity/temperature at epoch_end\n",
    "        \n",
    "#     \"\"\"\n",
    "    \n",
    "#     def __init__(self, corpus, sequence_length, step, diversity_list = [0.2, 0.5, 1.0, 1.2]):\n",
    "#         self.corpus = corpus\n",
    "#         self.sequence_length = sequence_length\n",
    "#         self.step = step\n",
    "#         self.diversity_list = diversity_list\n",
    "        \n",
    "#     def on_epoch_end(self, epoch, logs=None):\n",
    "#         start_index = random.randint(0, len(self.corpus) - self.sequence_length - 1)\n",
    "#         # create a seed\n",
    "#         original_sentence = self.corpus[start_index : start_index + self.sequence_length]\n",
    "                                        \n",
    "#         for diversity in self.diversity_list:\n",
    "#             self.generate_text(self.model, original_sentence, self.step, diversity)\n",
    "#             print()\n",
    "    \n",
    "#     def generate_text(self, model, original_sentence, step, temperature):\n",
    "#         \"\"\"\n",
    "#         Generates text from the `model` for `step` number \n",
    "#         of times (equivalent to total characters sampled), \n",
    "#         given the `original_sentence` (seed) and `temperature` value.\n",
    "\n",
    "#         Args:\n",
    "#         - model: LSTM model (Keras model)\n",
    "#         - original_sentence: text to be used as the starting seed for sampling (str)\n",
    "#         - step: number times that you'd want to sample. \n",
    "#                     ... translates to total chars to be sampled (int)\n",
    "#         - temperature: Temperature parameter for softmax function in `sample` (int)\n",
    "#         \"\"\"\n",
    "\n",
    "#         # get the original sentence\n",
    "#         sentence = original_sentence\n",
    "\n",
    "#         print(f\"Generating with this sentence... '{original_sentence}'\")\n",
    "#         print(\"Temperature/Diversity value:\", temperature)\n",
    "\n",
    "#         generated_sentence = \"\"\n",
    "#         for i in range(step):\n",
    "#             seed = vectorize_sentence(sentence) # shape-> (1,20,36)\n",
    "\n",
    "#             # get the softmax prediction\n",
    "#             predictions=model.predict(seed)[0] # shape -> (20, 36)\n",
    "\n",
    "#             # sample the softmax prediction\n",
    "#             next_index = self.sample(predictions, temperature)\n",
    "\n",
    "#             # convert next_index into character\n",
    "#             next_char = int2char[next_index]\n",
    "\n",
    "#             # append on our generated sentence\n",
    "#             generated_sentence += next_char\n",
    "\n",
    "#             # move the \"sentence\" (input) to the right by one char \n",
    "#             ## and append the predicted next_char\n",
    "#             sentence = sentence[1:] + next_char\n",
    "\n",
    "#         print(f\"Generated: {generated_sentence}\")\n",
    "#         print()\n",
    "\n",
    "#     def sample(predictions, temperature=0.2):\n",
    "#         \"\"\"\n",
    "#         Function to sample from the LSTM Softmax distribution \n",
    "#         (as opposed to greedy search - argmax)\n",
    "\n",
    "#         Args: \n",
    "#         - predictions: LSTM softmax output of shape (MAX_SEQ_LEN, N_UNIQUE_CHARS)\n",
    "#         - temperature: temperature parameter for softmax function. \n",
    "#                         ... Provides diversity to the sample\n",
    "#                         ... the higher the temperature, the less confident the model \n",
    "#                                about its pred (int)\n",
    "\n",
    "#         Returns:\n",
    "#         - max value from the probability distribution of softmax sampling (int) \n",
    "#         \"\"\"\n",
    "#         # convert into numpy array\n",
    "#         predictions = np.asarray(predictions).astype(\"float64\")\n",
    "\n",
    "#         # perform softmax sampling\n",
    "#         ## the higher the temperature, the less confident the model about its pred\n",
    "#         predictions = np.log(predictions) / temperature\n",
    "#         exp_preds = np.exp(predictions)\n",
    "#         predictions = exp_preds / np.sum(exp_preds)\n",
    "#         probas = np.random.multinomial(1, predictions, 1)\n",
    "\n",
    "#         return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "gradient": {
     "id": "e05a5f13-8d76-44cb-b906-57a0e6011fa2",
     "kernelId": ""
    },
    "id": "Y_pPmk1VDZ66",
    "outputId": "d4789d49-49c4-41c2-8e6e-90f04f9c08b8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " 8991/11514 [======================>.......] - ETA: 3:45 - loss: 1.0993 - accuracy: 0.6481"
     ]
    }
   ],
   "source": [
    "total_epochs = 10\n",
    "BATCH_SIZE=64\n",
    "\n",
    "# callback function that sets different learning rate at each epoch\n",
    "lr_callback = LearningRateScheduler(lambda epoch: 1e-3 * 1000 ** (epoch / total_epochs))\n",
    "\n",
    "# callback function to save model checkpoints\n",
    "checkpoint_path = path / \"models/one_hot/model_cp_lr.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path, \n",
    "                                                 save_weights_only=True, \n",
    "                                                 verbose=1)\n",
    "lr_history = model.fit(X_data, y_data, epochs = total_epochs, verbose = 1, batch_size=BATCH_SIZE, callbacks=[lr_callback, cp_callback])\n",
    "model.save(path / \"models/Char_LSTM_LOTR_OneHot_LR.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "id": "59a5f6ad-5fd4-45c6-9711-e4ec90a16dac",
     "kernelId": ""
    },
    "id": "NKUmNt2kGl4A"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOm+ECngVXDGQ8S0ITSaHy1",
   "collapsed_sections": [],
   "include_colab_link": true,
   "mount_file_id": "1OmlyCV6rsW5onXuEjxCM_y18jvmbq7yC",
   "name": "LOTR_LSTM_Character_Level_OneHot.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
